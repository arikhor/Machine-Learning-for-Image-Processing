{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 285 MLIP Assignment 2 - CNNs and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arik Horodniceanu A53285765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.4517e-42, 0.0000e+00],\n",
      "        [0.0000e+00, 9.9184e-39, 0.0000e+00]])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5,3)\n",
    "print(x)\n",
    "print(x.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x is initialized as a zero tensor of floating point values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3703, 0.1867, 0.1076],\n",
      "        [0.4567, 0.6128, 0.9207],\n",
      "        [0.6963, 0.7389, 0.1949],\n",
      "        [0.5142, 0.3140, 0.2071],\n",
      "        [0.2204, 0.4856, 0.8149]])\n",
      "torch.FloatTensor\n",
      "tensor([[-1.4256, -0.0723, -0.6979],\n",
      "        [ 2.0232, -0.1713, -1.1022],\n",
      "        [-0.3693,  0.1674, -0.3972],\n",
      "        [ 0.4700, -1.4627,  0.3014],\n",
      "        [-1.4162, -0.4298,  0.3880]])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "print(y)\n",
    "print(y.type())\n",
    "y = torch.randn(5,3)\n",
    "print(y)\n",
    "print(y.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.rand() returns a tensor of values sampled from a uniform distribution [0,1). torch.randn() returns a tensor of values sampled from a standard normal distribution, ie gaussian with mean 0 and variance 1. Both are tensors of floating point values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.4517e-42, 0.0000e+00],\n",
      "        [0.0000e+00, 9.9184e-39, 0.0000e+00]], dtype=torch.float64)\n",
      "tensor([[-1.4256, -0.0723, -0.6979],\n",
      "        [ 2.0232, -0.1713, -1.1022],\n",
      "        [-0.3693,  0.1674, -0.3972],\n",
      "        [ 0.4700, -1.4627,  0.3014],\n",
      "        [-1.4162, -0.4298,  0.3880]], dtype=torch.float64)\n",
      "torch.DoubleTensor\n",
      "torch.DoubleTensor\n"
     ]
    }
   ],
   "source": [
    "x = x.double()\n",
    "y = y.double()\n",
    "print(x)\n",
    "print(y)\n",
    "print(x.type())\n",
    "print(y.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type displayed is torch.float64, ie double precision tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[-0.1859, 1.3970, 0.5236],\n",
    "                [ 2.3854, 0.0707, 2.1970],\n",
    "                [-0.3587, 1.2359, 1.8951],\n",
    "                [-0.1189, -0.1376, 0.4647],\n",
    "                [-1.8968, 2.0164, 0.1092]])\n",
    "y = torch.Tensor([[ 0.4838, 0.5822, 0.2755],\n",
    "                [ 1.0982, 0.4932, -0.6680],\n",
    "                [ 0.7915, 0.6580, -0.5819],\n",
    "                [ 0.3825, -1.1822, 1.5217],\n",
    "                [ 0.6042, -0.2280, 1.3210]])\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are tensors of size 5x3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "z = torch.stack((x,y))\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n",
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "z1 = torch.cat((x,y),0)\n",
    "z2 = torch.cat((x,y),1)\n",
    "print(z1.shape)\n",
    "print(z2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of z is 2x5x3. torch.cat concatenates both tensors into a 2D tensor, just along different axes (rows or columns). The result is still a 2D tensor, as opposed to torch.stack() which creates a 3D tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3210)\n",
      "tensor(1.3210)\n"
     ]
    }
   ],
   "source": [
    "print(y[4,2])\n",
    "print(z[1,4,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value is 1.321."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1092, 1.3210])\n"
     ]
    }
   ],
   "source": [
    "print(z[:,4,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 elements, one corresponding to each of the stacked tensors x,y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n"
     ]
    }
   ],
   "source": [
    "print(x + y)\n",
    "print(torch.add(x, y))\n",
    "print(x.add(y))\n",
    "torch.add(x, y, out=x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All print the same output, they are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8)\n",
    "print(x.size(),y.size(),z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1st command creates a 4x4 tensor of values from a standard normal distribution, the 2nd reshapes it into a 1d array of length 16 and the 3rd reshapes it into a 2x8 tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[22.7134, 23.4689]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(10,10)\n",
    "y = torch.rand(2,100)\n",
    "x = x.view(1,100)\n",
    "y = y.view(100,2)\n",
    "print(torch.mm(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1x100)(100x2) = 1x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 NumPy and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "torch.FloatTensor <class 'numpy.ndarray'> float32\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(a.type(),type(b),b.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a is a tensor of floating point numbers, b is an ndarray (Numpy array) of floating point numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 1., 1., 1., 1.])\n",
      "[2. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a[0] +=1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, they match. b points to the same memory location as a, so its value has also changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 2., 2., 2., 2.]) [3. 2. 2. 2. 2.]\n",
      "tensor([4., 3., 3., 3., 3.]) [4. 3. 3. 3. 3.]\n",
      "tensor([5., 4., 4., 4., 4.]) [4. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a,b)\n",
    "a[:] +=1\n",
    "print(a,b)\n",
    "a = a.add(1)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these operations are equivalent, adding 1 to each element in a. However, for the last operation since there is an assignment to a (a=...), the value of b does not change since the memory pointed to has changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a,1,out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing as before, a is a numpy ndarray, b is a tensor of floating point numbers and since they reference the same area in memory their values remain the same when adding 1 to a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "7.175905704498291\n",
      "0.03749561309814453\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "t1 = time.time()\n",
    "x = torch.randn(5, 3).to(device)\n",
    "t2 = time.time()\n",
    "print(str(t2-t1))\n",
    "\n",
    "t1 = time.time()\n",
    "y = torch.randn(5, 3, device=device)\n",
    "t2 = time.time()\n",
    "print(str(t2-t1))\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second command is much faster (~2 orders of magnitude) since the tensor is created on GPU directly rather than creating it on CPU and transfering to GPU which is slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1938,  0.9088,  0.4392],\n",
      "        [-0.8614, -1.2590,  0.1905],\n",
      "        [ 0.2335,  1.0373,  0.5423],\n",
      "        [-0.7413, -1.8596,  1.8363],\n",
      "        [ 0.1444, -0.1994,  1.7531]], device='cuda:0') tensor([[-1.3939,  0.8653,  0.2188],\n",
      "        [ 0.7309,  0.8124, -1.3547],\n",
      "        [-1.4945,  1.1921, -0.0900],\n",
      "        [-0.9002, -0.0709, -0.6154],\n",
      "        [ 0.7127, -0.7959, -0.8818]], device='cuda:0') tensor([[-1.2000,  1.7741,  0.6580],\n",
      "        [-0.1305, -0.4465, -1.1642],\n",
      "        [-1.2610,  2.2294,  0.4523],\n",
      "        [-1.6415, -1.9306,  1.2209],\n",
      "        [ 0.8572, -0.9953,  0.8713]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first command checks if there's a GPU unit available. Next it moves a random 5x3 tensor to GPU (x), creates one at GPU (y) and then adds them together. The 2nd command is faster, as moving tensors created on CPU to GPU is much slower than just creating them on GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.200048    1.7740563   0.6579717 ]\n",
      " [-0.13049299 -0.44654912 -1.1641661 ]\n",
      " [-1.2610004   2.2294064   0.45232165]\n",
      " [-1.6414716  -1.9305704   1.2209041 ]\n",
      " [ 0.85715485 -0.9952726   0.8712884 ]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-11d5c486e6eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "print(z.cpu().numpy())\n",
    "print(z.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First one can move to numpy array on CPU. Second instruction is not valid, need to move it to CPU first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Autograd: Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,2,requires_grad=True)\n",
    "print(x)\n",
    "y = x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "print (y.requires_grad)\n",
    "print (x.grad,y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y*3\n",
    "f = z.mean()\n",
    "print(z,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{x} = (x_1,x_2,x_3,x_4) \\\\ \\textbf{y} = (x_1+2, x_2+2, x_3+2, x_4+2) \\\\ \\textbf{z} = (3(x_1+2)^2,3(x_2+2)^2,3(x_3+2)^2,3(x_4+2)^2)$$\n",
    "$$f = \\frac{1}{4}\\sum_{i=1}^4{z_i} = \\frac{3}{4}\\sum_{i=1}^4{(x_i+2)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "f.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla_xf(\\textbf{x}))_i=4.5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla_xf(\\textbf{x}))_i=2*\\frac{3}{4}(x_i+2)=[x_i = 1]=4.5$$\n",
    "Theoretically sound result, correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 MNIST Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MNISTtools\n",
    "xtrain, ltrain = MNISTtools.load(dataset='training')\n",
    "xtest, ltest = MNISTtools.load(dataset='testing')\n",
    "\n",
    "# Same function as assignment 1\n",
    "def normalize_MNIST_images(x):\n",
    "    normalized=x.astype(np.float32)\n",
    "    normalized-=127.5\n",
    "    normalized/=127.5\n",
    "    return normalized\n",
    "\n",
    "\n",
    "xtrain = normalize_MNIST_images(xtrain)\n",
    "xtest = normalize_MNIST_images(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) (10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "xtrain = np.reshape(xtrain,(28,28,1,60000))\n",
    "xtest = np.reshape(xtest,(28,28,1,10000))\n",
    "xtrain = np.moveaxis(xtrain,[1, 0, 2, 3], [3, 2, 1,0])\n",
    "xtest = np.moveaxis(xtest,[1, 0, 2, 3], [3, 2, 1,0])\n",
    "print(xtrain.shape,xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct, according to batch size $\\times$ num of input channels $\\times$ height $\\times$ width."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as pyplot\n",
    "MNISTtools.show(xtrain[42,0,:,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our old friend, number 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = torch.from_numpy(xtrain)\n",
    "ltrain = torch.from_numpy(ltrain)\n",
    "xtest = torch.from_numpy(xtest)\n",
    "ltest = torch.from_numpy(ltest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Convolutional Neural Network (CNN) for MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After convolution 1: 6x24x24 (28-5+1 = 24)\n",
    "\n",
    "After pool 1: 6x12x12 (24/2 = 12)\n",
    "\n",
    "After convolution 2: 16x8x8 (12-5+1 = 8)\n",
    "\n",
    "After pool 2: 16x4x4 (8/2 = 4)\n",
    "\n",
    "The first number refers to how many, the other 2 refer to the dimensions.\n",
    "\n",
    "The third layer, which is a FC layer has 16x4x4 = 256 input units from the 2nd pool layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# This is our neural networks class that inherits from nn.Module\n",
    "class LeNet(nn.Module):\n",
    "# Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(256,120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    # Here we define one forward pass through the network\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x ):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)\n",
    "    \n",
    "net = LeNet()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function just defines the layers in the network according to the definition. The auxillary function flattens the features to 1d for the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5]) True\n",
      "conv1.bias torch.Size([6]) True\n",
      "conv2.weight torch.Size([16, 6, 5, 5]) True\n",
      "conv2.bias torch.Size([16]) True\n",
      "fc1.weight torch.Size([120, 256]) True\n",
      "fc1.bias torch.Size([120]) True\n",
      "fc2.weight torch.Size([84, 120]) True\n",
      "fc2.bias torch.Size([84]) True\n",
      "fc3.weight torch.Size([10, 84]) True\n",
      "fc3.bias torch.Size([10]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of the convolutional layers are according to batch size  ×  num of input channels  × height  × width , like section 22. \n",
    "\n",
    "The parameters for the FC layers are just the number of inputs and outputs, like section 25. The bias can be thought of as an extra dimension, so it's always going to be 1x[same dimension as its accompanying layer]. \n",
    "\n",
    "All gradients are going to be tracked by autograd, since .requires_grad is True for all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.2900)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yinit = net(xtest)\n",
    "    \n",
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred.int()).float().mean())\n",
    "#print(100*(ltest==lpred).float().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This initializes the network and checks the accuracy of classification on the test set. Does that by comparing the predicted labels to test labels. Accuracy is 10.29% without backprop after first pass only. Note there was a bug for me with the code given, so I made a slight modification. This has no effect on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See full function next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.294\n",
      "[1,   200] loss: 2.279\n",
      "[1,   300] loss: 2.250\n",
      "[1,   400] loss: 2.168\n",
      "[1,   500] loss: 1.801\n",
      "[1,   600] loss: 1.036\n",
      "[2,   100] loss: 0.714\n",
      "[2,   200] loss: 0.574\n",
      "[2,   300] loss: 0.495\n",
      "[2,   400] loss: 0.447\n",
      "[2,   500] loss: 0.393\n",
      "[2,   600] loss: 0.365\n",
      "[3,   100] loss: 0.329\n",
      "[3,   200] loss: 0.315\n",
      "[3,   300] loss: 0.284\n",
      "[3,   400] loss: 0.273\n",
      "[3,   500] loss: 0.254\n",
      "[3,   600] loss: 0.243\n"
     ]
    }
   ],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    N = xtrain.size()[0] # Training set size\n",
    "    NB = int((N+B-1)/B) # Number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=gamma, momentum=rho)\n",
    "    for epoch in range(T):\n",
    "        running_loss = 0.0\n",
    "        shuffled_indices = np.random.permutation(range(N))\n",
    "        for k in range(NB):\n",
    "            t = shuffled_indices[k]\n",
    "            # Extract k-th minibatch from xtrain and ltrain\n",
    "            minibatch_indices = shuffled_indices[B*k:min(B*(k+1), N)]\n",
    "            inputs = xtrain[minibatch_indices]\n",
    "            labels = ltrain[minibatch_indices]\n",
    "            # Initialize the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            # Forward propagation\n",
    "            outputs = net(inputs)\n",
    "            # Error evaluation\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            # Back propagation\n",
    "            loss.backward()\n",
    "            # Parameter update\n",
    "            optimizer.step()\n",
    "            # Print averaged loss per minibatch every 100 mini-batches\n",
    "            # Compute and print statistics\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if k % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' %(epoch+1,k+1,running_loss/100))\n",
    "                running_loss = 0.0\n",
    "    \n",
    "net = LeNet()\n",
    "backprop_deep(xtrain, ltrain, net, T=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty similar results to what was expected, loss decreases considerably with backprop, indicating test results will also improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(93.2300)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    yinit = net(xtest)\n",
    "    \n",
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred.int()).float().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "93.23% accuracy compared to ~12.8% before. Backprop does make the network learn, clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "net = LeNet().to(device)\n",
    "xtrain=xtrain.to(device)\n",
    "ltrain=ltrain.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.300\n",
      "[1,   200] loss: 2.293\n",
      "[1,   300] loss: 2.285\n",
      "[1,   400] loss: 2.272\n",
      "[1,   500] loss: 2.248\n",
      "[1,   600] loss: 2.186\n",
      "[2,   100] loss: 1.975\n",
      "[2,   200] loss: 1.397\n",
      "[2,   300] loss: 0.798\n",
      "[2,   400] loss: 0.565\n",
      "[2,   500] loss: 0.452\n",
      "[2,   600] loss: 0.393\n",
      "[3,   100] loss: 0.353\n",
      "[3,   200] loss: 0.313\n",
      "[3,   300] loss: 0.284\n",
      "[3,   400] loss: 0.246\n",
      "[3,   500] loss: 0.237\n",
      "[3,   600] loss: 0.210\n",
      "[4,   100] loss: 0.188\n",
      "[4,   200] loss: 0.201\n",
      "[4,   300] loss: 0.181\n",
      "[4,   400] loss: 0.181\n",
      "[4,   500] loss: 0.169\n",
      "[4,   600] loss: 0.159\n",
      "[5,   100] loss: 0.154\n",
      "[5,   200] loss: 0.142\n",
      "[5,   300] loss: 0.140\n",
      "[5,   400] loss: 0.133\n",
      "[5,   500] loss: 0.149\n",
      "[5,   600] loss: 0.129\n",
      "[6,   100] loss: 0.121\n",
      "[6,   200] loss: 0.120\n",
      "[6,   300] loss: 0.129\n",
      "[6,   400] loss: 0.123\n",
      "[6,   500] loss: 0.117\n",
      "[6,   600] loss: 0.115\n",
      "[7,   100] loss: 0.121\n",
      "[7,   200] loss: 0.111\n",
      "[7,   300] loss: 0.104\n",
      "[7,   400] loss: 0.100\n",
      "[7,   500] loss: 0.103\n",
      "[7,   600] loss: 0.095\n",
      "[8,   100] loss: 0.097\n",
      "[8,   200] loss: 0.097\n",
      "[8,   300] loss: 0.095\n",
      "[8,   400] loss: 0.093\n",
      "[8,   500] loss: 0.099\n",
      "[8,   600] loss: 0.099\n",
      "[9,   100] loss: 0.089\n",
      "[9,   200] loss: 0.085\n",
      "[9,   300] loss: 0.087\n",
      "[9,   400] loss: 0.087\n",
      "[9,   500] loss: 0.081\n",
      "[9,   600] loss: 0.097\n",
      "[10,   100] loss: 0.075\n",
      "[10,   200] loss: 0.076\n",
      "[10,   300] loss: 0.086\n",
      "[10,   400] loss: 0.086\n",
      "[10,   500] loss: 0.082\n",
      "[10,   600] loss: 0.080\n"
     ]
    }
   ],
   "source": [
    "backprop_deep(xtrain, ltrain, net, T=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training was significantly faster, less than a minute for 10 epochs compared to ~2 minutes for 3 epochs on CPU. Also much lower training loss, implying the test results may be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(97.8200)\n"
     ]
    }
   ],
   "source": [
    "xtest = xtest.cuda()\n",
    "yinit = net(xtest)\n",
    "    \n",
    "_, lpred = yinit.max(1)\n",
    "lpred=lpred.cpu()\n",
    "print(100 * (ltest == lpred.int()).float().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed test accuracy increased to ~97.8% from ~93.2% due to more epochs, significant improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
